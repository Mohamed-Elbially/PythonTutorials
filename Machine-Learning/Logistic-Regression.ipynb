{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import normalize,scale\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression using Sklearn package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        50\n",
      "          1       1.00      1.00      1.00        50\n",
      "\n",
      "avg / total       1.00      1.00      1.00       100\n",
      "\n",
      "[[50  0]\n",
      " [ 0 50]]\n",
      "Coefficients: [[ 0.81091424 -1.16601465  1.52533197  1.5428075 ]]\n",
      "\n",
      "Bias: [ 0.10503024] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Iris = datasets.load_iris() # Iris dataset \n",
    "Iris_Data = Iris.data       # extract Iris data\n",
    "Iris_Target = Iris.target   # extract Iris targets\n",
    "\n",
    "data = Iris_Data[:100,:]     # Extract 2 class data instead of the 3 class\n",
    "target = Iris_Target[:100]   # Extract 2 class target instead of the 3 class\n",
    "\n",
    "normalized_data = normalize(data, norm = 'l2') #Normalize the data\n",
    "standarized_data = scale(data) #Standarize the data\n",
    "\n",
    "lr = LogisticRegression()        # Initialize the logistic regression model \n",
    "lr.fit(standarized_data,target)  # train the model\n",
    "\n",
    "predictedLabels = lr.predict(standarized_data) # test the model on the training data\n",
    "# print a report about classification performance \n",
    "print (metrics.classification_report(target,predictedLabels)) \n",
    "# Print confusion matrix \n",
    "print (metrics.confusion_matrix(target,predictedLabels))\n",
    "print 'Coefficients: {v}\\n'.format(v = lr.coef_) # Print weights \n",
    "print 'Bias: {v} \\n'.format(v = lr.intercept_)   # print bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEZCAYAAACAZ8KHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f815d18a6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ActivationFunctions (object):\n",
    "    \"\"\"\n",
    "    This class generates different well-knwon activation functions\n",
    "    x : is the data to apply the activation function on it.\n",
    "    Defaukt value is np.linspace(-10,10,1000)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__ (self,x = np.linspace(-10,10,1000)):\n",
    "        self.data = x\n",
    "        self.y = self.Sigmoid()\n",
    "    \n",
    "    def Sigmoid(self):\n",
    "        self.y = 1.0 / (1+np.exp(-self.data))\n",
    "        return self.y\n",
    "    \n",
    "    def ReLU(self):\n",
    "        self.y = np.maximum(0,self.data)\n",
    "        return self.y\n",
    "    \n",
    "    def Tanh(self):\n",
    "        self.y = np.tanh(self.data)\n",
    "        return self.y\n",
    "    \n",
    "    def UnitStep(self):\n",
    "        self.y = np.where(self.data>=0 , 1,0)\n",
    "        return self.y\n",
    "    \n",
    "    def DrawActivationFunction (self):\n",
    "        plt.plot(self.data,self.y)\n",
    "        plt.title ('Activation Function')\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('F(x)')\n",
    "    \n",
    "activationFn = ActivationFunctions()\n",
    "y = activationFn.Tanh()\n",
    "activationFn.DrawActivationFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CostFunctions (object):\n",
    "    \n",
    "    def __init__ (self, target=[], predictedLabels=[]):\n",
    "        self.target = target\n",
    "        self.predictedLabels = predictedLabels\n",
    "    \n",
    "    def NLL (self):\n",
    "        pass\n",
    "    \n",
    "    def MSE (self):\n",
    "        pass\n",
    "    \n",
    "    def CrossEntropy(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CostGradientFunctions (object):\n",
    "    \n",
    "    def __init__ (self, target=[], data=[], weights=[]):\n",
    "        self.data = data\n",
    "        slef.target = target\n",
    "        slef.weights = weights\n",
    "    \n",
    "    def NLLGradient (self):\n",
    "        pass\n",
    "    \n",
    "    def MSEGradient (self):\n",
    "        pass\n",
    "    \n",
    "    def CrossEntropyGradient(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Update Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class WeightUpdateRules (object):\n",
    "    \n",
    "    def __init__ (self,data=[],target=[],weights=[],batchSize=1,eta=0.01,epochs = 100):\n",
    "        self.target = target  \n",
    "        self.data = data\n",
    "        self.weights = weights\n",
    "        self.batchSize = batchSize\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "        slef.costError = []\n",
    "        #slef.activationFn = ActivationFunctions()\n",
    "        #self.costFn = CostFunctions()\n",
    "        #self.costGradientFn = CostGradientFunctions()\n",
    "        \n",
    "    def GD (self):\n",
    "        for _ in np.arange(epochs):\n",
    "            z = NetInput(self.data,self.weights)\n",
    "            activationFn = ActivationFunctions(x=z)\n",
    "            yPredicted = activationFn.Sigmoid()\n",
    "            costGradientFn = CostGradientFunctions()\n",
    "            costGradient = costGradientFn.NLLGradient()\n",
    "            costErrorFn = CostFunctions()\n",
    "            costErr = costErrorFn.NLL()\n",
    "            self.costError.push(costErr)\n",
    "            self.weights += self.eta*costGradient         \n",
    "            \n",
    "    def SGD (self):\n",
    "        for _ in np.arange(epochs):\n",
    "            costErr = 0\n",
    "            for record in self.data:\n",
    "                z = NetInput(record,self.weights)\n",
    "                activationFn = ActivationFunctions(x=z)\n",
    "                yPredicted = activationFn.Sigmoid()\n",
    "                costGradientFn = CostGradientFunctions()\n",
    "                costGradient = costGradientFn.NLLGradient()\n",
    "                costErrorFn = CostFunctions()\n",
    "                costErr += costErrorFn.NLL()\n",
    "                self.weights += self.eta*costGradient\n",
    "                \n",
    "            self.costError.push(costErr)\n",
    "    \n",
    "    def BatchSGD (self):\n",
    "        for _ in np.arange(epochs):\n",
    "            costErr = 0\n",
    "            for batch in batches:\n",
    "                z = NetInput(batch,self.weights)\n",
    "                activationFn = ActivationFunctions(x=z)\n",
    "                yPredicted = activationFn.Sigmoid()\n",
    "                costGradientFn = CostGradientFunctions()\n",
    "                costGradient = costGradientFn.NLLGradient()\n",
    "                costErrorFn = CostFunctions()\n",
    "                costErr += costErrorFn.NLL()\n",
    "                self.weights += self.eta*costGradient\n",
    "                \n",
    "            self.costError.push(costErr)\n",
    "    \n",
    "    def NetInput (self,x,w):\n",
    "        return np.dot(x,w)\n",
    "    \n",
    "    def iter_minibatches(self):\n",
    "    # Provide chunks one by one\n",
    "    chunkstartmarker = 0\n",
    "    while chunkstartmarker < numtrainingpoints:\n",
    "        chunkrows = range(chunkstartmarker,chunkstartmarker+chunksize)\n",
    "        X_chunk, y_chunk = getrows(chunkrows)\n",
    "        yield X_chunk, y_chunk\n",
    "        chunkstartmarker += chunksize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression using plain python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression2 (object):\n",
    "    \n",
    "    def __init__(self, eta=0.01, epochs=50):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def fit (slef,data, target):\n",
    "        pass\n",
    "    \n",
    "    def predict (self,z):\n",
    "        np.where (z>0.5,1,0)\n",
    "    \n",
    "    def NetInput (self,x,w):\n",
    "        return np.dot(x,w)\n",
    "    \n",
    "    def PlotCostError(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test LogisticRegression2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Iris = datasets.load_iris() # Iris dataset \n",
    "Iris_Data = Iris.data       # extract Iris data\n",
    "Iris_Target = Iris.target   # extract Iris targets\n",
    "\n",
    "data = Iris_Data[:100,:]     # Extract 2 class data instead of the 3 class\n",
    "target = Iris_Target[:100]   # Extract 2 class target instead of the 3 class\n",
    "\n",
    "normalized_data = normalize(data, norm = 'l2') #Normalize the data\n",
    "standarized_data = scale(data) #Standarize the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
